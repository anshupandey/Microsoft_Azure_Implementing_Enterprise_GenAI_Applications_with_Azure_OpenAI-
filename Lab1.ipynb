{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qm8x2zhhd-8"
      },
      "source": [
        "# Integrating tools/function with LLM using Azure OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu6uxcLphsRz",
        "outputId": "dcee60be-8dfc-4600-e9e7-a89b5f7b163d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GTT0Jc-qhVby"
      },
      "outputs": [],
      "source": [
        "# Define constants for the Azure OpenAI API configuration\n",
        "api_key = \"xxxxxxxxxxxxxx\"\n",
        "api_version = \"2023-07-01-preview\" # \"2023-05-15\"\n",
        "azure_endpoint = \"https://xxxxxxxxx.openai.azure.com/\"\n",
        "model_name = \"gpt-35-turbo\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PLKRALkuhVby"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "import json\n",
        "import requests\n",
        "\n",
        "client = AzureOpenAI(\n",
        "  azure_endpoint = azure_endpoint, \n",
        "  api_key=api_key,  \n",
        "  api_version=api_version\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMs1SliPer2Q"
      },
      "source": [
        "In an API call, you can describe functions and have the model intelligently choose to output a JSON object containing arguments to call one or many functions. The Chat Completions API does not call the function; instead, the model generates JSON that you can use to call the function in your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6voT6dEZOEQ"
      },
      "source": [
        "## Supported models\n",
        "Not all model versions are trained with function calling data. Function calling is supported with the following models: gpt-4, gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-4-0613, gpt-3.5-turbo, gpt-3.5-turbo-0125, gpt-3.5-turbo-1106, and gpt-3.5-turbo-0613\n",
        "\n",
        "In addition, parallel function calls is supported on the following models: gpt-4-turbo-preview, gpt-4-0125-preview, gpt-4-1106-preview, gpt-3.5-turbo-0125, and gpt-3.5-turbo-1106"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FUAVQTH1FCob"
      },
      "outputs": [],
      "source": [
        "# Define the OpenWeatherMap API key\n",
        "OWM_API_KEY = \"29af1cea50a401d8e624eea4660b3f59\"\n",
        "\n",
        "def get_current_weather(location, unit=\"kelvin\"):\n",
        "    \"\"\"\n",
        "    Fetches the current weather information for a given location.\n",
        "\n",
        "    Parameters:\n",
        "    - location: str, the name of the location (e.g., \"Paris\").\n",
        "    - unit: str, the unit of temperature (default is \"kelvin\").\n",
        "\n",
        "    Returns:\n",
        "    - str: JSON formatted string containing weather information.\n",
        "    \"\"\"\n",
        "    # Construct the API request URL\n",
        "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={location}&appid={OWM_API_KEY}\"\n",
        "    \n",
        "    # Send the API request\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    # Parse the temperature and weather forecast from the response\n",
        "    temp = response.json()['main']['temp']\n",
        "    forecast = [response.json()['weather'][0]['main'], response.json()['weather'][0]['description']]\n",
        "\n",
        "    # Create a dictionary with the weather information\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": temp,\n",
        "        \"unit\": 'Kelvin',\n",
        "        \"forecast\": forecast\n",
        "    }\n",
        "    \n",
        "    # Return the weather information as a JSON string\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zvpewsATGB30",
        "outputId": "01d29cea-3467-4fc5-b124-8f38b473468f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"location\": \"Paris\", \"temperature\": 290.43, \"unit\": \"Kelvin\", \"forecast\": [\"Rain\", \"light rain\"]}'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_current_weather(\"Paris\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sTPInk2CiVpV",
        "outputId": "bbd31641-53d2-4f91-d578-9d5ec50c4e03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"location\": \"Manila\", \"temperature\": 304.47, \"unit\": \"Kelvin\", \"forecast\": [\"Clouds\", \"overcast clouds\"]}'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_current_weather(\"Manila\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OLj1VFabUCR",
        "outputId": "cb038e0a-fc95-4c8f-9f14-f783a84f494e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9bNSMJQblXNxi55gX0f1pLPk5l7h3\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"AI stands for Artificial Intelligence. It refers to the simulation of human intelligence in machines that are programmed to perform tasks that would normally require human intelligence, such as visual perception, speech recognition, problem-solving, learning, and decision-making. AI enables machines to process and analyze large amounts of data, identify patterns, and make autonomous decisions or predictions. It utilizes various techniques like machine learning, neural networks, natural language processing, and computer vision to mimic human intelligence.\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      },\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1718695330,\n",
            "  \"model\": \"gpt-35-turbo\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 91,\n",
            "    \"prompt_tokens\": 11,\n",
            "    \"total_tokens\": 102\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\":\"user\",'content':\"what is AI?\"}]\n",
        "results = client.chat.completions.create(model = model_name, messages = messages)\n",
        "print(results.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Define tools/functions for the LLM to use\n",
        "tools = [\n",
        "        {\n",
        "            \"type\": \"function\",\n",
        "            \"function\": {\n",
        "                \"name\": \"get_current_weather\",\n",
        "                \"description\": \"Get the current weather in a given location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
        "                        },\n",
        "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\",\"kelvin\"]},\n",
        "                    },\n",
        "                    \"required\": [\"location\"],\n",
        "                },\n",
        "            },\n",
        "        },   \n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9gdvGUJGbheA"
      },
      "outputs": [],
      "source": [
        "def get_response(messages, tools, model=model_name):\n",
        "    \"\"\"\n",
        "    Handles interaction with the LLM, including making function calls if needed.\n",
        "\n",
        "    Parameters:\n",
        "    - messages: list, the conversation history.\n",
        "    - tools: list, the functions/tools available to the LLM.\n",
        "    - model: str, the model name to use (default is model_name).\n",
        "\n",
        "    Returns:\n",
        "    - str: The response from the LLM or function.\n",
        "    \"\"\"\n",
        "    # Create a chat completion with the given messages and tools\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice='auto',\n",
        "        temperature=0.2,\n",
        "    )\n",
        "    #print(response.model_dump_json(indent=2))\n",
        "    # Get the generated response and tool calls (if any)\n",
        "    response = response.choices[0].message\n",
        "    tool_calls = response.tool_calls\n",
        "\n",
        "    try:\n",
        "        if tool_calls:\n",
        "            print(\"Making a function call\")\n",
        "            # Available functions\n",
        "            available_functions = {\n",
        "                \"get_current_weather\": get_current_weather,\n",
        "            }\n",
        "            print(tool_calls)\n",
        "\n",
        "            # Extend conversation with assistant's reply\n",
        "            messages.append(response)\n",
        "\n",
        "            # Handle each function call\n",
        "            for tool_call in tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_to_call = available_functions[function_name]\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "                function_response = function_to_call(**function_args)\n",
        "                messages.append(\n",
        "                    {\n",
        "                        \"tool_call_id\": tool_call.id,\n",
        "                        \"role\": \"tool\",\n",
        "                        \"name\": function_name,\n",
        "                        \"content\": function_response,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            # Get a new response from the model with the function response\n",
        "            second_response = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=messages,\n",
        "            )\n",
        "            return second_response\n",
        "        else:\n",
        "            return response.content\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred\", e)\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWL0wVqFdeBm",
        "outputId": "af1791a3-7e05-4527-e75e-9caefe8bd685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9bNr00U46cFQDLker3zxluTwSIvHf\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"AI, or Artificial Intelligence, refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It involves the development of computer systems that can perform tasks that would typically require human intelligence, such as speech recognition, problem-solving, and decision-making.\",\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": null\n",
            "      },\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1718696858,\n",
            "  \"model\": \"gpt-35-turbo\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 56,\n",
            "    \"prompt_tokens\": 87,\n",
            "    \"total_tokens\": 143\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "AI, or Artificial Intelligence, refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It involves the development of computer systems that can perform tasks that would typically require human intelligence, such as speech recognition, problem-solving, and decision-making.\n"
          ]
        }
      ],
      "source": [
        "# Example usage of get_response function\n",
        "messages = [{\"role\": \"user\", \"content\": \"Provide a 2 line explanation for AI\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0H4DaivdmPW",
        "outputId": "67d2c2f0-8be3-41c2-aee4-7f115fadf366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-9bNrC4vy2ReOwPc1QPfNQh6sChtRb\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"tool_calls\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [\n",
            "          {\n",
            "            \"id\": \"call_FfE6kse2GSyJL63Fqb9nWR0Z\",\n",
            "            \"function\": {\n",
            "              \"arguments\": \"{\\n  \\\"location\\\": \\\"Tokyo\\\"\\n}\",\n",
            "              \"name\": \"get_current_weather\"\n",
            "            },\n",
            "            \"type\": \"function\"\n",
            "          }\n",
            "        ]\n",
            "      },\n",
            "      \"content_filter_results\": {}\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1718696870,\n",
            "  \"model\": \"gpt-35-turbo\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 17,\n",
            "    \"prompt_tokens\": 87,\n",
            "    \"total_tokens\": 104\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Making a function call\n",
            "[ChatCompletionMessageToolCall(id='call_FfE6kse2GSyJL63Fqb9nWR0Z', function=Function(arguments='{\\n  \"location\": \"Tokyo\"\\n}', name='get_current_weather'), type='function')]\n",
            "The weather in Tokyo today is rainy with showers. The temperature is around 291.81 Kelvin.\n"
          ]
        }
      ],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"How is the weather in Tokyo today?\"}]\n",
        "response = get_response(messages, tools)\n",
        "print(response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
